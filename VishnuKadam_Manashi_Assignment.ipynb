{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb63581",
   "metadata": {},
   "source": [
    "#### Vishnu_Kadam_MANASHI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f59f7",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\n",
    "#### Why general Purpose LLMs are insufficient ?\n",
    "General purpose LLMs are trained with specific benchmarks in mind. AI labs focus on popular advertisable metrics related to question answersing, coding, maths, etc. The task of mental health and related qa's is not a major priority. This is evident through the technical reports of popular open models like deepseekV2 [1] and kimi-k2 [2].When these general purpose models are used their training forces them to focus more on answering questions and keeping user engaged in a question answer loop instead of prioritizing the mental health of the user. This leads to vague or misleading answers being generated by the models, which can be harmful when interacting with vulnerable individuals. There are various documented instances of this happening[3]. \n",
    "\n",
    "---\n",
    "\n",
    "#### Loss\n",
    "To reduce the chances of the model ignoring critical clinical mental health facts, we use the following loss formulation during training\n",
    "\n",
    "We assume there are $N$ clinical categories indexed by $i \\in \\{1,\\dots,N\\}$, each assigned an importance rank $i$ ($i = 1$ is least important, $i = N $ is most important). Let $p \\in \\mathbb{N}$ be a hyperparameter controlling the strength of prioritization.\n",
    "\n",
    "The unnormalized weight for category $i$ is\n",
    "$$\n",
    "w_i = i^{p}.\n",
    "$$\n",
    "\n",
    "The normalized weights are\n",
    "$$\n",
    "\\tilde{w}_i = \\frac{i^{p}}{\\sum_{j=1}^{N} j^{p}}.\n",
    "$$\n",
    "\n",
    "If $\\ell_i$ denotes the loss associated with category $i$, the final clinical riskâ€“weighted loss is\n",
    "$$\n",
    "\\mathcal{L}_{\\text{clinical}}\n",
    "=\n",
    "\\sum_{i=1}^{N}\n",
    "\\tilde{w}_i \\, \\ell_i\n",
    "=\n",
    "\\sum_{i=1}^{N}\n",
    "\\left(\n",
    "\\frac{i^{p}}{\\sum_{j=1}^{N} j^{p}}\n",
    "\\right)\n",
    "\\ell_i.\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Uncertainty Visualisation\n",
    "The model uncertainty can be directly integrated as an additional UI layer only available to the clinicians. This will work in the following way.\n",
    "\n",
    " Once the text is generated, entropy will be calculated for the output tokens using methods similar to task C and depending on it's value the tokens will be colored  <span style=\"background: red;\">red </span>  <span style=\"background: yellow;\">yellow </span>  <span style=\"background: green;\">green </span> respectively. This overlay can further be optimized such that instead of showing a seperate color for each token, which will lead to a lot of visual clutter, we can calculate the frequency of high entropy tokens per paragraph/sentence, and color the <span style=\"background: red;\">entire paragraph/sentence </span> to show that these sections need more consideration. This way the user can interact with the chat interface similar to any other chat based llms, and the clinicians can quicky glance the underlying uncertainty present in the generated text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe50fb3",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0271b",
   "metadata": {},
   "source": [
    "Ambiguous speakers are handled by assuming that most question will be asked by the therapist. So if the sentence contains a ? and the speaker is unknown, assume them to be therapist. Overlapping speech is handled by arranging the transcript in ascending time order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ecc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## demo transcripts\n",
    "# 1. Depression Transcript\n",
    "transcript_depression = [\n",
    "    {\"time\": \"09:00\", \"speaker\": \"Therapist\", \"text\": \"How have things been since we last met?\"},\n",
    "    {\"time\": \"09:01\", \"speaker\": \"Client\", \"text\": \"I've been feeling so heavy. I haven't slept in 4 days.\"},\n",
    "    {\"time\": \"09:02\", \"speaker\": \"Therapist\", \"text\": \"That's a long time to go without rest. Are you having dark thoughts?\"},\n",
    "    {\"time\": \"09:04\", \"speaker\": \"Client\", \"text\": \"Sometimes I just want to give up and end it.\"},\n",
    "    {\"time\": \"09:05\", \"speaker\": \"Therapist\", \"text\": \"I'm glad you shared that with me. Let's create a safety plan. We will review your emergency contacts next session.\"}\n",
    "]\n",
    "\n",
    "# 2. Anxiety Transcript\n",
    "transcript_anxiety = [\n",
    "    {\"time\": \"14:15\", \"speaker\": \"Client\", \"text\": \"My heart keeps racing every time I leave the house. I feel anxious constantly.\"},\n",
    "    {\"time\": \"14:16\", \"speaker\": \"Therapist\", \"text\": \"That sounds incredibly exhausting. When did this spike start?\"},\n",
    "    {\"time\": \"14:18\", \"speaker\": \"Client\", \"text\": \"It's been constant for 3 weeks now. I can barely focus.\"},\n",
    "    {\"time\": \"14:20\", \"speaker\": \"Therapist\", \"text\": \"What specific thoughts go through your mind when the racing starts?\"}\n",
    "]\n",
    "\n",
    "# 3. Schizophrenia Transcript\n",
    "transcript_schizophrenia = [\n",
    "    {\"time\": \"11:30\", \"speaker\": \"Client\", \"text\": \"The voices have been very loud for 2 days. They won't stop.\"},\n",
    "    {\"time\": \"11:31\", \"speaker\": \"Therapist\", \"text\": \"Are they telling you to hurt yourself?\"},\n",
    "    {\"time\": \"11:32\", \"speaker\": \"Client\", \"text\": \"No, just whispering criticisms. But it's exhausting to listen to.\"},\n",
    "    {\"time\": \"11:35\", \"speaker\": \"Therapist\", \"text\": \"We'll discuss adjusting your antipsychotic dosage next time.\"}\n",
    "]\n",
    "\n",
    "# 4. Bipolar Disorder Transcript\n",
    "transcript_bipolar = [\n",
    "    {\"time\": \"16:00\", \"speaker\": \"Client\", \"text\": \"I feel amazing! I've been awake for 48 hours working on a new business plan.\"},\n",
    "    {\"time\": \"16:01\", \"speaker\": \"Therapist\", \"text\": \"Being awake that long without feeling tired is something we need to monitor.\"},\n",
    "    {\"time\": \"16:02\", \"speaker\": \"Client\", \"text\": \"Why? I feel better than ever, so calm and powerful.\"},\n",
    "    {\"time\": \"16:05\", \"speaker\": \"Therapist\", \"text\": \"How have you been managing your finances during this burst of energy?\"}\n",
    "]\n",
    "\n",
    "# 5. OCD Transcript\n",
    "transcript_ocd = [\n",
    "    {\"time\": \"10:00\", \"speaker\": \"Client\", \"text\": \"I spent 5 hours checking the locks on my doors yesterday.\"},\n",
    "    {\"time\": \"10:02\", \"speaker\": \"Therapist\", \"text\": \"That sounds exhausting. What happens if you try to stop checking?\"},\n",
    "    {\"time\": \"10:03\", \"speaker\": \"Client\", \"text\": \"I get physically sick. I feel terribly anxious until I do it again.\"},\n",
    "    {\"time\": \"10:08\", \"speaker\": \"Therapist\", \"text\": \"Let's practice some grounding and exposure techniques next session.\"}\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1f1c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"observations\": [\n",
      "        \"[10:01] Yes, my heart keeps racing.\"\n",
      "    ],\n",
      "    \"objective_facts\": [\n",
      "        \"[10:00] I haven't slept in three days.\"\n",
      "    ],\n",
      "    \"emotional_trajectory\": [\n",
      "        {\n",
      "            \"time\": \"10:01\",\n",
      "            \"state\": \"Negative\"\n",
      "        }\n",
      "    ],\n",
      "    \"risk_flags\": [],\n",
      "    \"open_loops_for_next_session\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def process_session(transcript):\n",
    "    output = {\n",
    "        \"observations\" : [],\n",
    "        \"objective_facts\" : [],\n",
    "        \"emotional_trajectory\": [],\n",
    "        \"risk_flags\": [],\n",
    "        \"open_loops_for_next_session\": []\n",
    "    }\n",
    "    objective_patterns = [r'\\b(\\d+)\\s*(days|weeks|months|years|hours)\\b', r'\\b(slept|awake)\\b']\n",
    "    risk_keywords = ['suicide', 'end it', 'kill myself', 'give up', 'hurt myself']\n",
    "    emotion_lexicon = {'anxious': -1, 'racing': -1, 'exhausting': -1, 'better': 1, 'calm': 1}\n",
    "    # Sort by timestamp to handle overlapping speech/edge cases\n",
    "    transcript.sort(key=lambda x: x.get('time', '00:00'))\n",
    "    \n",
    "    current_emotion_score = 0\n",
    "    \n",
    "    for i, turn in enumerate(transcript):\n",
    "        speaker = turn.get(\"speaker\", \"Unknown\")\n",
    "        text = turn.get(\"text\", \"\").lower()\n",
    "        time = turn.get(\"time\", \"\")\n",
    "        \n",
    "        # Resolve ambiguous speakers by context (if it's a question, likely therapist)\n",
    "        if speaker == \"Unknown\":\n",
    "            speaker = \"Therapist\" if \"?\" in text else \"Client\"\n",
    "\n",
    "        if speaker == \"Client\":\n",
    "            # 1. Subjective Observations & 2. Objective Facts\n",
    "            has_objective = False\n",
    "            for pattern in objective_patterns:\n",
    "                if re.search(pattern, text):\n",
    "                    output[\"objective_facts\"].append(f\"[{time}] {turn['text']}\")\n",
    "                    has_objective = True\n",
    "                    break\n",
    "            \n",
    "            if not has_objective:\n",
    "                output[\"observations\"].append(f\"[{time}] {turn['text']}\")\n",
    "\n",
    "            # 3. Risk Flags\n",
    "            if any(risk in text for risk in risk_keywords):\n",
    "                output[\"risk_flags\"].append(f\"URGENT [{time}]: {turn['text']}\")\n",
    "                \n",
    "            # Track Emotional Trajectory\n",
    "            for word, score in emotion_lexicon.items():\n",
    "                if word in text:\n",
    "                    current_emotion_score += score\n",
    "                    state = \"Negative\" if current_emotion_score < 0 else \"Positive\"\n",
    "                    output[\"emotional_trajectory\"].append({\"time\": time, \"state\": state})\n",
    "\n",
    "        elif speaker == \"Therapist\":\n",
    "            # 4. Open Loops (Questions asked at the end or explicit forward-looking statements)\n",
    "            if \"?\" in text and i == len(transcript) - 1:\n",
    "                output[\"open_loops_for_next_session\"].append(turn['text'])\n",
    "            if \"next time\" in text or \"next session\" in text:\n",
    "                output[\"open_loops_for_next_session\"].append(turn['text'])\n",
    "\n",
    "    return json.dumps(output, indent=4)\n",
    "\n",
    "# Test with the provided input example\n",
    "transcript_input = [\n",
    "    {\"time\": \"10:00\", \"speaker\": \"Client\", \"text\": \"I haven't slept in three days.\"},\n",
    "    {\"time\": \"10:01\", \"speaker\": \"Therapist\", \"text\": \"That sounds exhausting. Are you feeling anxious?\"},\n",
    "    {\"time\": \"10:01\", \"speaker\": \"Client\", \"text\": \"Yes, my heart keeps racing.\"}\n",
    "]\n",
    "\n",
    "print(process_session(transcript_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f8861",
   "metadata": {},
   "source": [
    "## Part C\n",
    "### C1\n",
    "Architecture of LLaMA-3.2-1B information flow during forward pass.\n",
    "The model has a vocab size of 128256, i.e it recognizes 128k different tokens, and each individual token is a 2048 dimensional vector.\n",
    "\n",
    "Let's say we input 4 tokens. [101, 102, 104, 108] shape = 4\n",
    "\n",
    "##### Step 1 : Embedding lookup table\n",
    "Here, use the indices of the 4 tokens from the input to look up their respective embeddings, which in case of llama-3.2-1B are 2048 dimensional vectors.\n",
    "\n",
    "Current size: [4 x 2048]\n",
    "\n",
    "##### Step 2: Transformer layers\n",
    "\n",
    "Here, first the input goes through a normalization layer (RMSNorm). Size doesn't change.\n",
    "\n",
    "Llama uses grouped query attention (GQA). In GQA, the dimension of query matrix is different from key and value matrix. Here the dimensions of q_proj, k_proj, and v_proj matrices are 2048 x 2048, 2048 x 512, 2048 x 512 respectively.\n",
    "\n",
    "So after the matrix multiplications, the q_proj_out  is 4 x 2048 and the k_proj_out and v_proj_out is 4 x 512 respectively. RoPE embeddings are added here.\n",
    "\n",
    "Llama uses multihead attention, where the process of calculation attention is done in 32 different heads for query part and 8 heads in key and value part.\n",
    "\n",
    "Note: 32 = 8*4. i.e 4 query heads share  a key-value head (K-V duplicated 4 times ). This is the reason this type of attention is called qrouped query attention.\n",
    "\n",
    "Note: the q_proj_out has dimension of 4 x 2048, inorder to create 32 heads from this matrix, we reshape the matrix into the shize 32 x 4 x 64. Now we have 32 heads 4 tokens and 64 dimensional embedding. For K and V the matrix size is 8 x 4 x 64.\n",
    "\n",
    "The attention scores are calculates using $Q \\times K^{T}$. So, their dimension is 32 x 4 x 4. After multiplying with V matrix our final output size for a single grouped attention is 32 x 4 x 64. \n",
    "\n",
    "The outputs of the  32 heads are flattened to 4 x 2048 and then is multiplied by a new out_proj matrix which functions as a way to mix the information up. out_proj matrix has the size 2048 x 2048. We add the residual connection from the input. The final dimension is still 4 x 2048.\n",
    "\n",
    "The outputs are then normalized using RMSNorm. Followed by the mlp block containing gate, up and down projection matrices\n",
    "\n",
    "The outputs are multiplied by the gate 2048 x 8192 and up 2048 x 8192 dimensional matrics parallely. The SilU activation function is applied after gate matrix output and it is added element by element to the up matrix output. The final dimension after this is 4 x 8192. This is followed by a down projection matrix to reduce dimension to the original input size of 4 x 8192. We add another residual connection from the previous part before MLP layer. \n",
    "\n",
    "\n",
    "This transformer layer is repeated 16 times and the output of the final layer is normalized. The output dimension still is 4 x 2048. We multiply this with a final lm_head matrix of size 2048 x 128256, this gives logits over our vocab. We do a final softmax of the lm_head matrix layer, and choose the relevent tokens depending on our generation strategy.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9569a98f",
   "metadata": {},
   "source": [
    "### C2\n",
    "\n",
    "I've chose the final MLP layer. The below code uses two different parameters, threshold and suppression factor. The core idea here is check if the absolute value of the mlp output is greater then the fixed threshold value. If so, we will multiply the output with a small suppression factor < 1. This will reduce highly confident model outputs as these high values when pass through the softmax will lead to high probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60567736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "class ClinicalSafetyMLPHook:\n",
    "    def __init__(self, threshold=5.0, suppression_factor=0.2):\n",
    "        \"\"\"\n",
    "        threshold: The magnitude at which an activation is considered an \"outlier\" (overconfident).\n",
    "        suppression_factor: How much to scale down the outlier activation (0.2 = reduce to 20%).\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.suppression_factor = suppression_factor\n",
    "\n",
    "    def __call__(self, module, input, output):\n",
    "       \n",
    "        activation = output[0] if isinstance(output, tuple) else output\n",
    "\n",
    "        \n",
    "        mask = torch.where(\n",
    "            torch.abs(activation) > self.threshold,\n",
    "            torch.tensor(self.suppression_factor, dtype=activation.dtype, device=activation.device),\n",
    "            torch.tensor(1.0, dtype=activation.dtype, device=activation.device)\n",
    "        )\n",
    "        \n",
    "        # Apply the filter element-wise\n",
    "        modified_activation = activation * mask\n",
    "\n",
    "       \n",
    "\n",
    "        if isinstance(output, tuple):\n",
    "            return (modified_activation,) + output[1:]\n",
    "        return modified_activation\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load Model\n",
    "# -------------------------\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# Load on CPU to ensure it runs easily in a standard notebook environment\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# -------------------------\n",
    "# 2. Register the Hook\n",
    "# -------------------------\n",
    "# Target the final MLP layer as requested\n",
    "target_layer = model.model.layers[-1].mlp\n",
    "\n",
    "handle = target_layer.register_forward_hook(\n",
    "    ClinicalSafetyMLPHook(threshold=5.0, suppression_factor=0.2)\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 3. Run Forward Pass\n",
    "# -------------------------\n",
    "dummy_input = torch.tensor([[101, 202, 303]])\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "\n",
    "print(\"Forward pass completed. Outlier MLP activations successfully gated.\")\n",
    "\n",
    "# Clean up the hook\n",
    "handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe905ef6",
   "metadata": {},
   "source": [
    "Q. Which part of this assignment challenged your understanding the most?\n",
    "-> Part C: As it made me look into the llama architecture in a greater detail than I have ever done and figure out the ins and outs of the model. I learned at lot about GQA and LlamaMLP(gate, up, down project) layers from this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7937d8bc",
   "metadata": {},
   "source": [
    "Q. If you had one more week to work on this, how would you improve your solutions?\n",
    "-> The filtering part used in the part C is very primitive. I've checked that it does have some effect in changing the model outputs, but given more time I would have turned my attention on the GQA layer. The idea here would be to first get the attention scores (softmax probabilities) for each head, and filter the high entropy tokens there. This method could be better than current method because even though I use thresholding and llama uses layernorms, it could be that all model outputs after the final mlp layer are above my threshold and I am always supressing my output. Working with softmax probabilities make choseing a correct threshold easier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45f7712",
   "metadata": {},
   "source": [
    "Q. In your opinion, what is one aspect of the therapeutic relationship that can never be automated?\n",
    "-> Humans are social creatures. Even if the job of a clinical therapist can be automated, I believe that the act to opening up to a person and discussing your issues cannot be abstracted away using automation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeabd98",
   "metadata": {},
   "source": [
    "###### REFERENCES\n",
    "1. https://arxiv.org/pdf/2501.12948\n",
    "2. https://arxiv.org/pdf/2507.20534\n",
    "3. https://www.bbc.com/news/articles/cgerwp7rdlvo\n",
    "4. https://chatgpt.com/share/6999d505-d150-8001-93c2-42ced78e908a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e30336a",
   "metadata": {},
   "source": [
    "###### AI disclosure\n",
    "In Part A, ChatGTP was used only for latex formatting\n",
    "\n",
    "In Part B, Gemini was used to create demo data, and code, I have manually checked each line and ran the code to ensure it's correctness.\n",
    "\n",
    "In Part C, Gemini was used to learn about the llama architecture and for researching papers related to hallucination dampening. I've checked the correctness of the generated code by using it in google collab to verify, if thresholding indeed does have any effect in changing model generated text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
